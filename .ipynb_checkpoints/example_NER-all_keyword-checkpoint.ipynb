{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f04f354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import six\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from transformers import TFElectraModel, TFBertModel\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Activation, Lambda, Input\n",
    "# from tensorflow_addons.layers import CRF\n",
    "# from crf import CRF\n",
    "# from keras_contrib.layers import CRF\n",
    "# from keras_contrib.losses import crf_loss\n",
    "# from keras_contrib.metrics import crf_viterbi_accuracy\n",
    "\n",
    "# from tf_crf_layer.layer import CRF\n",
    "# from tf_crf_layer.loss import crf_loss\n",
    "# from tf_crf_layer.metrics import crf_accuracy\n",
    "\n",
    "from tf2crf import CRF, ModelWithCRFLoss, ModelWithCRFLossDSCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a513c391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('../../electra/pretrained_model/nscc_mecab_base/vocab.txt', do_lower_case=False)\n",
    "tokenizer = BertTokenizer.from_pretrained('vocab.txt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf67d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas = pd.read_csv('NER_ids_label_rev_index_1030.csv')\n",
    "\n",
    "x_data = df_datas['summary'].tolist()\n",
    "# x_data = df_datas['text'].tolist()[:int(len(df_datas)/4)]\n",
    "y_data = df_datas['NER_ids'].tolist()\n",
    "for i in range(len(y_data)):\n",
    "    y_data[i] = [int(i) for i in (y_data[i][1:-1].split())]\n",
    "str_y_data = df_datas['NER_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccee454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 86538 / Test : 37088\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=72)\n",
    "\n",
    "print(f\"Train : {len(train_x)} / Test : {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd11f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb3dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/86538 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 86538/86538 [03:52<00:00, 372.75it/s]\n"
     ]
    }
   ],
   "source": [
    "encode_train_data = []\n",
    "input_ids =[]\n",
    "attention_masks =[]\n",
    "token_type_ids =[]\n",
    "for line in tqdm(train_x):\n",
    "    encoded_dict = tokenizer.encode_plus(line, \\\n",
    "                                         add_special_tokens = True,\\\n",
    "                                         pad_to_max_length=True,\\\n",
    "                                         max_length=MAX_LENGTH, \n",
    "                                        return_attention_mask=True,\n",
    "                                        truncation = True)\n",
    "\n",
    "    input_id=encoded_dict['input_ids']\n",
    "    attention_mask=encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "    token_type_ids.append(token_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6759aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text :   평가지역 전국 대상해충 돌발 해충 2종, 남방계 해충 2종 평가방법 기후변화 시나리오에 따른 세대수 및 국내 분포 지역 변화 분석 국내 분포 및 환경 요인과의 관계 분석을 통한 환경 적합도 분석\n",
      "Tokenizer Text :  ['평가', '##지역', '전국', '대상', '##해충', '돌발', '해충', '2종', '[UNK]', '남', '##방', '##계', '해충', '2종', '평가방법', '기후변화', '시나리오에', '따른', '세대', '##수', '및', '국내', '분포', '지역', '변화', '분석', '국내', '분포', '및', '환경', '요인과', '##의', '관계', '분석을', '통한', '환경', '적합', '##도', '분석']\n",
      "Encode Text :  [2, 4027, 4600, 8319, 4262, 6745, 16374, 8675, 9583, 1, 319, 2156, 2161, 8675, 9583, 11852, 5682, 19118, 4067, 9133, 2231, 847, 4063, 5161, 4218, 4173, 3999, 4063, 5161, 847, 4098, 23717, 2105, 4867, 4375, 4016, 4098, 4527, 2177, 3999, 3]\n"
     ]
    }
   ],
   "source": [
    "train_input_ids=np.array(input_ids, dtype=int)\n",
    "train_attention_masks=np.array(attention_masks, dtype=int)\n",
    "train_token_type_ids=np.array(token_type_ids, dtype=int)\n",
    "train_x=(train_input_ids, train_attention_masks, train_token_type_ids)\n",
    "\n",
    "print(\"Original Text : \", x_data[0])\n",
    "print(\"Tokenizer Text : \", tokenizer.tokenize(x_data[0]))\n",
    "print(\"Encode Text : \", (tokenizer.encode(x_data[0], add_special_tokens = True, max_length=MAX_LENGTH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb7daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    2,    10, 10086, ..., 16183,  4155,     3],\n",
       "       [    2, 25822, 12049, ...,     0,     0,     0],\n",
       "       [    2,  5443,  5601, ...,  3999,  4327,     3],\n",
       "       ...,\n",
       "       [    2,  6526,  2125, ...,  5598,  4501,     3],\n",
       "       [    2, 11992,  2437, ...,     0,     0,     0],\n",
       "       [    2, 11979,  6192, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ca185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780fcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ner_to_index_rev_1030.json\", 'rb') as f:\n",
    "    ner_to_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5427cecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "vocab_size = len(tokenizer)\n",
    "tag_size = len(ner_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22adf025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "bert (TFBertMainLayer)       TFBaseModelOutputWithPool 177853440 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256, 256)          196864    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256, 256)          65792     \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    ((None, 256), (None, 256, 591110    \n",
      "=================================================================\n",
      "Total params: 178,707,206\n",
      "Trainable params: 178,707,204\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_with_crf_loss\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_1 (Functional)    ((None, 256), (None, 256, 178707206 \n",
      "_________________________________________________________________\n",
      "accuracy (Accuracy)          multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 178,707,210\n",
      "Trainable params: 178,707,204\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "    bert_layers = model.get_layer('bert')\n",
    "    input_layer = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype='int32') # [(None, 256)]\n",
    "    bert_l = bert_layers(input_layer)[0]\n",
    "\n",
    "    # X = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(electra_l)\n",
    "    X = tf.keras.layers.Dropout(0.1)(bert_l)\n",
    "\n",
    "    X = tf.keras.layers.Dropout(0.1)(X)\n",
    "    X = tf.keras.layers.Dense(units=256, activation=\"relu\")(X)\n",
    "    X = tf.keras.layers.Dropout(0.1)(X)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(MAX_LENGTH, activation=\"relu\")(X) # negative loss를 피하기 위해서 relu 함수를 사용해준다? -> 효과 없음\n",
    "    #     output_layer = tf.keras.layers.Dense(MAX_LENGTH,activation='softmax')(X)\n",
    "    crf = CRF(units=tag_size)\n",
    "    output_layer = crf(output_layer)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    print(model.summary())\n",
    "    model = ModelWithCRFLoss(model, sparse_target=True)\n",
    "#     model = ModelWithCRFLossDSCLoss(model, sparse_target=True)\n",
    "    model.build(input_shape=(None, MAX_LENGTH))\n",
    "    print(model.summary())\n",
    "#     model.build(input_shape=(None, MAX_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5dc9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:1'):\n",
    "#     model = TFElectraModel.from_pretrained('../nscc_mecab_base/torch_model', from_pt=True)\n",
    "#     electra_layers = model.get_layer('electra')\n",
    "#     input_layer = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype='int32') # [(None, 256)]\n",
    "#     electra_l = electra_layers(input_layer)[0]\n",
    "\n",
    "#     # X = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(electra_l)\n",
    "#     X = tf.keras.layers.Dropout(0.1)(electra_l)\n",
    "\n",
    "#     X = tf.keras.layers.Dropout(0.1)(X)\n",
    "#     X = tf.keras.layers.Dense(units=256, activation=\"relu\")(X)\n",
    "#     X = tf.keras.layers.Dropout(0.1)(X)\n",
    "\n",
    "#     output_layer = tf.keras.layers.Dense(MAX_LENGTH, activation=\"relu\")(X) # negative loss를 피하기 위해서 relu 함수를 사용해준다? -> 효과 없음\n",
    "#     #     output_layer = tf.keras.layers.Dense(MAX_LENGTH,activation='softmax')(X)\n",
    "#     crf = CRF(units=tag_size)\n",
    "#     output_layer = crf(output_layer)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "#     print(model.summary())\n",
    "#     model = ModelWithCRFLoss(model, sparse_target=True)\n",
    "# #     model = ModelWithCRFLossDSCLoss(model, sparse_target=True)\n",
    "#     model.build(input_shape=(None, MAX_LENGTH))\n",
    "#     print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00cfbf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "#     model.compile(\n",
    "#             optimizer='adam'\n",
    "#         )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "        loss = keras.losses.CategoricalCrossentropy(),\n",
    "#         metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)]\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0847927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc = '21.10.30-1'\n",
    "# checkpoint_filepath = \"checkpoints/electra_NER_\" + desc + \"/electra_{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "# model.save_weights(checkpoint_filepath.format(epoch=0))\n",
    "\n",
    "desc = '21.10.31-1'\n",
    "checkpoint_filepath = \"checkpoints/bert_NER_\" + desc + \"/electra_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "model.save_weights(checkpoint_filepath.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf3674c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "1576/1576 [==============================] - ETA: 0s - loss: 209.6151 - accuracy: 0.8838WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,val_loss_val,val_val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1576/1576 [==============================] - 1938s 1s/step - loss: 209.6151 - accuracy: 0.8838 - val_loss_val: 101.2789 - val_val_accuracy: 0.9439\n",
      "Epoch 2/100\n",
      "1576/1576 [==============================] - ETA: 0s - loss: 84.7150 - accuracy: 0.9484WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,val_loss_val,val_val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1576/1576 [==============================] - 1944s 1s/step - loss: 84.7150 - accuracy: 0.9484 - val_loss_val: 74.8291 - val_val_accuracy: 0.9518\n",
      "Epoch 3/100\n",
      "1576/1576 [==============================] - ETA: 0s - loss: 58.8503 - accuracy: 0.9598WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,val_loss_val,val_val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1576/1576 [==============================] - 1950s 1s/step - loss: 58.8503 - accuracy: 0.9598 - val_loss_val: 56.5373 - val_val_accuracy: 0.9610\n",
      "Epoch 4/100\n",
      "1576/1576 [==============================] - ETA: 0s - loss: 41.0235 - accuracy: 0.9702WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,val_loss_val,val_val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1576/1576 [==============================] - 1958s 1s/step - loss: 41.0235 - accuracy: 0.9702 - val_loss_val: 46.4508 - val_val_accuracy: 0.9676\n",
      "Epoch 5/100\n",
      "1123/1576 [====================>.........] - ETA: 8:22 - loss: 30.2759 - accuracy: 0.9772"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fd7eb9392f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         save_freq=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss_val', patience=3) # 아직 데이터가 너무 적어서 val_loss 계산이 안되서 경고가 나옴\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "#         save_freq=2\n",
    "    )\n",
    "    history = model.fit(train_x, train_y, batch_size=BATCH_SIZE, validation_split=0.2, epochs=100, callbacks=[callback, model_checkpoint_callback])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "218a58a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1870 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 1870/1870 [00:04<00:00, 385.25it/s]\n"
     ]
    }
   ],
   "source": [
    "encode_test_data = []\n",
    "input_ids =[]\n",
    "attention_masks =[]\n",
    "token_type_ids =[]\n",
    "# for line in tqdm(test_x):\n",
    "for line in tqdm(test_x):\n",
    "    encoded_dict = tokenizer.encode_plus(line, \\\n",
    "                                         add_special_tokens = True,\\\n",
    "                                         pad_to_max_length=True,\\\n",
    "                                         max_length=MAX_LENGTH, \n",
    "                                        return_attention_mask=True,\n",
    "                                        truncation = True)\n",
    "\n",
    "    input_id=encoded_dict['input_ids']\n",
    "    attention_mask=encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "    token_type_ids.append(token_type_id)\n",
    "\n",
    "test_input_ids=np.array(input_ids, dtype=int)\n",
    "test_attention_masks=np.array(attention_masks, dtype=int)\n",
    "test_token_type_ids=np.array(token_type_ids, dtype=int)\n",
    "test_x=(test_input_ids, test_attention_masks, test_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66bfb61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/electra_NER_21.10.30-1/electra_0011.ckpt\n"
     ]
    }
   ],
   "source": [
    "desc = '21.10.30-1'\n",
    "checkpoint_filepath = \"checkpoints/electra_NER_\" + desc + \"/electra_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4f96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_his = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0125050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test_y = []\n",
    "for ids_list in test_y:\n",
    "    for ids in ids_list:\n",
    "        report_test_y.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfbf14ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167936"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(report_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312c447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
